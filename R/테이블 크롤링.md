# 1. 웹 테이블 크롤링

## 1) 정적 페이지

테이블을 스크래핑 해야 한다. 테이블 태그를 찾고, tr태그를 찾고, td를 읽는 방식으로 할 수도 있지만,`

`xml` 패키지의 `readHTMLTable()` 를 통해 쉽게 받아올 수 있다. (테이블 객체의 돔 객체를 첫번째 아규먼트로 준다.) 

전체를 읽어와 데이터프레임으로 저장할 수 있다는 뜻이다. 

하나의 HTML 에 여러 테이블이 있을 수도 있다.

```R
library(XML)
library(rvest)
url = "https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population"
read1 <- read_html(url)
read2 <- htmlParse(read1)
first_table <- getNodeSet(read2,"//table")[[1]]
xt <- readHTMLTable(first_table)
str(xt)
head(xt)
```



## 2) 동적 페이지

읽어오고자 하는 테이블이 동적으로 처리해야 하는 경우 . .. 



```R


# http://www.airkorea.or.kr/ : 한국환경공단 실시간 자료 조회
# 테이블을 한방에 읽어오자 : 동적페이지
library(RSelenium)
remDr <- remoteDriver(remoteServerAddr = "localhost" , port = 4445, browserName = "chrome")
remDr$open()
url <- "http://www.airkorea.or.kr/web/pmRelay?itemCode=11008&pMENU_NO=109"
remDr$navigate(url)

webElem <- remDr$findElement(using = "css", "#dateDiv_1 > img")
webElem$clickElement()
Sys.sleep(1)
webElem <- remDr$findElement(using = "css", "#ui-datepicker-div > table > tbody > tr:nth-child(2) > td:nth-child(6) > a")
webElem$clickElement()
Sys.sleep(1)
webElem <- remDr$findElement(using = "css", "#cont_body > form > div > div > a:nth-child(1)")
webElem$clickElement()
Sys.sleep(3)

library(XML)
elem <- remDr$findElement(using="css", value=".st_1")
elemtxt <- elem$getElementAttribute("outerHTML")
# HTML 의 경우에 XML 패키지에서 적용하므로
elem_html <- htmlTreeParse(elemtxt, asText = TRUE, useInternalNodes = T, encoding="UTF-8")

Sys.setlocale("LC_ALL", "English") # 영어만 있을 때는 오류가 난다.  한글이 깨져서..
games_table <- readHTMLTable(elem_html, header = T, stringsAsFactors = FALSE)[[1]]
Sys.setlocale() # 다시 원상복구

Encoding(names(games_table)) <- "UTF-8"
head(games_table)
str(games_table)
View(games_table)
tail(games_table)
Sys.getlocale()

```



